# Maze Solver vá»›i Reinforcement Learning

Dá»± Ã¡n nÃ y triá»ƒn khai cÃ¡c thuáº­t toÃ¡n há»c tÄƒng cÆ°á»ng (Reinforcement Learning) Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n tÃ¬m Ä‘Æ°á»ng trong mÃª cung. Dá»± Ã¡n bao gá»“m 3 thuáº­t toÃ¡n chÃ­nh: Q-Learning, SARSA vÃ  Deep Q-Network (DQN).

## ğŸ“‹ Má»¥c lá»¥c

- [Giá»›i thiá»‡u](#giá»›i-thiá»‡u)
- [Cáº¥u trÃºc dá»± Ã¡n](#cáº¥u-trÃºc-dá»±-Ã¡n)
- [YÃªu cáº§u há»‡ thá»‘ng](#yÃªu-cáº§u-há»‡-thá»‘ng)
- [CÃ i Ä‘áº·t](#cÃ i-Ä‘áº·t)
- [HÆ°á»›ng dáº«n sá»­ dá»¥ng](#hÆ°á»›ng-dáº«n-sá»­-dá»¥ng)
- [Thuáº­t toÃ¡n](#thuáº­t-toÃ¡n)
- [Káº¿t quáº£](#káº¿t-quáº£)
- [TÃ¡c giáº£](#tÃ¡c-giáº£)

## ğŸ¯ Giá»›i thiá»‡u

Dá»± Ã¡n nÃ y nghiÃªn cá»©u vÃ  so sÃ¡nh hiá»‡u quáº£ cá»§a cÃ¡c thuáº­t toÃ¡n há»c tÄƒng cÆ°á»ng trong viá»‡c giáº£i quyáº¿t bÃ i toÃ¡n tÃ¬m Ä‘Æ°á»ng trong mÃª cung. CÃ¡c thuáº­t toÃ¡n Ä‘Æ°á»£c triá»ƒn khai bao gá»“m:

- **Q-Learning**: Thuáº­t toÃ¡n off-policy cÆ¡ báº£n sá»­ dá»¥ng Q-table
- **SARSA**: Thuáº­t toÃ¡n on-policy sá»­ dá»¥ng Q-table
- **DQN**: Deep Q-Network sá»­ dá»¥ng máº¡ng neural Ä‘á»ƒ xáº¥p xá»‰ Q-function

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
maze-solver-project/
â”œâ”€â”€ backend/                           # Backend - Python
â”‚   â”œâ”€â”€ maze_generators/               # Thuáº­t toÃ¡n sinh mÃª cung
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_generator.py          # Lá»›p cÆ¡ sá»Ÿ cho sinh mÃª cung
â”‚   â”‚   â”œâ”€â”€ dfs_generator.py           # Thuáº­t toÃ¡n DFS
â”‚   â”‚   â”œâ”€â”€ prim_generator.py          # Thuáº­t toÃ¡n Prim
â”‚   â”‚   â””â”€â”€ wilson_generator.py        # Thuáº­t toÃ¡n Wilson
â”‚   â”‚
â”‚   â”œâ”€â”€ rl_agents/                     # Thuáº­t toÃ¡n há»c tÄƒng cÆ°á»ng
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_agent.py              # Lá»›p cÆ¡ sá»Ÿ cho cÃ¡c agent
â”‚   â”‚   â”œâ”€â”€ q_learning.py              # Thuáº­t toÃ¡n Q-Learning
â”‚   â”‚   â”œâ”€â”€ dqn_agent.py               # Thuáº­t toÃ¡n DQN
â”‚   â”‚   â””â”€â”€ sarsa.py                   # Thuáº­t toÃ¡n SARSA
â”‚   â”‚
â”‚   â”œâ”€â”€ enviroment/                    # MÃ´i trÆ°á»ng mÃª cung
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ maze_env.py                # Äá»‹nh nghÄ©a mÃ´i trÆ°á»ng mÃª cung
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                         # CÃ¡c tiá»‡n Ã­ch
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py                  # Cáº¥u hÃ¬nh vÃ  háº±ng sá»‘
â”‚   â”‚   â”œâ”€â”€ data_handler.py            # Xá»­ lÃ½ dá»¯ liá»‡u (lÆ°u/táº£i model)
â”‚   â”‚   â””â”€â”€ visualization.py           # Hiá»ƒn thá»‹ mÃª cung vÃ  káº¿t quáº£
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                        # LÆ°u mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
â”‚   â”‚   â”œâ”€â”€ q_learning/                # MÃ´ hÃ¬nh Q-Learning
â”‚   â”‚   â”œâ”€â”€ sarsa/                     # MÃ´ hÃ¬nh SARSA
â”‚   â”‚   â””â”€â”€ dqn/                       # MÃ´ hÃ¬nh DQN
â”‚   â”‚
â”‚   â”œâ”€â”€ static/                        # Frontend - Giao diá»‡n web
â”‚   â”‚   â””â”€â”€ index.html                 # Giao diá»‡n HTML chÃ­nh
â”‚   â”‚
â”‚   â”œâ”€â”€ results/                       # Káº¿t quáº£ Ä‘Ã¡nh giÃ¡
â”‚   â”‚   â”œâ”€â”€ q_learning_heatmaps/       # Heatmap Q-Learning
â”‚   â”‚   â”œâ”€â”€ sarsa_heatmaps/            # Heatmap SARSA
â”‚   â”‚   â”œâ”€â”€ dqn_heatmaps/              # Heatmap DQN
â”‚   â”‚   â””â”€â”€ comparison/                # Káº¿t quáº£ so sÃ¡nh
â”‚   â”‚
â”‚   â”œâ”€â”€ app.py                         # Web server Flask/FastAPI
â”‚   â”œâ”€â”€ training.py                    # Script huáº¥n luyá»‡n mÃ´ hÃ¬nh
â”‚   â”œâ”€â”€ evaluation.py                  # Script Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
â”‚   â””â”€â”€ get_heatmaps.py               # Script táº¡o heatmap
â”‚
â”œâ”€â”€ requirements.txt                   # Danh sÃ¡ch thÆ° viá»‡n cáº§n thiáº¿t
â””â”€â”€ README.md                         # TÃ i liá»‡u hÆ°á»›ng dáº«n
```

## ğŸ’» YÃªu cáº§u há»‡ thá»‘ng

- Python 3.8 trá»Ÿ lÃªn
- CUDA (tÃ¹y chá»n, cho DQN vá»›i GPU)
- RAM: tá»‘i thiá»ƒu 4GB
- Dung lÆ°á»£ng Ä‘Ä©a: 1GB

## ğŸš€ CÃ i Ä‘áº·t

### 1. Clone dá»± Ã¡n

```bash
git clone https://github.com/yourusername/maze-solver-project.git
cd maze-solver-project
```

### 2. Táº¡o mÃ´i trÆ°á»ng áº£o (khuyáº¿n nghá»‹)

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### 3. CÃ i Ä‘áº·t thÆ° viá»‡n

```bash
pip install -r requirements.txt
```

Ná»™i dung file `requirements.txt`:
```txt
numpy==1.24.3
matplotlib==3.7.1
torch==2.0.1
tqdm==4.65.0
seaborn==0.12.2
pandas==2.0.3
flask==3.0.0
flask-cors==4.0.0
```

## ğŸ“– HÆ°á»›ng dáº«n sá»­ dá»¥ng

### 1. Cháº¡y giao diá»‡n web

```bash
# Khá»Ÿi Ä‘á»™ng web server
python backend/app.py

# Má»Ÿ trÃ¬nh duyá»‡t vÃ  truy cáº­p
http://localhost:8000
```

Giao diá»‡n web cho phÃ©p:
- Chá»n thuáº­t toÃ¡n (Q-Learning, SARSA, DQN)
- Chá»n kÃ­ch thÆ°á»›c mÃª cung
- Theo dÃµi quÃ¡ trÃ¬nh huáº¥n luyá»‡n real-time
- Xem visualization cá»§a káº¿t quáº£
- So sÃ¡nh cÃ¡c thuáº­t toÃ¡n

### 2. Huáº¥n luyá»‡n mÃ´ hÃ¬nh (Command Line)

#### Huáº¥n luyá»‡n Q-Learning

```bash
# MÃª cung nhá» (11x11)
python backend/training.py --agent q_learning --maze dfs --size small --episodes 2000

# MÃª cung vá»«a (15x15)
python backend/training.py --agent q_learning --maze dfs --size medium --episodes 2000

# MÃª cung lá»›n (21x21)
python backend/training.py --agent q_learning --maze dfs --size large --episodes 3000

# Vá»›i tham sá»‘ tÃ¹y chá»‰nh
python backend/training.py --agent q_learning --maze dfs --size medium --episodes 2000 --lr 0.15 --epsilon 0.8 --decay 0.99
```

#### Huáº¥n luyá»‡n SARSA

```bash
# MÃª cung vá»«a (15x15)
python backend/training.py --agent sarsa --maze dfs --size medium --episodes 2000

# Vá»›i cÃ¡c loáº¡i mÃª cung khÃ¡c
python backend/training.py --agent sarsa --maze prim --size medium --episodes 2000
python backend/training.py --agent sarsa --maze wilson --size medium --episodes 2000
```

#### Huáº¥n luyá»‡n DQN

```bash
# MÃª cung vá»«a (15x15)
python backend/training.py --agent dqn --maze dfs --size medium --episodes 2000 --hidden-size 128 --batch-size 64

# MÃª cung lá»›n vá»›i GPU
python backend/training.py --agent dqn --maze dfs --size large --episodes 5000 --hidden-size 256 --batch-size 128
```

#### Tham sá»‘ huáº¥n luyá»‡n

| Tham sá»‘ | MÃ´ táº£ | GiÃ¡ trá»‹ máº·c Ä‘á»‹nh |
|---------|-------|------------------|
| `--agent` | Thuáº­t toÃ¡n (q_learning, sarsa, dqn) | q_learning |
| `--maze` | Loáº¡i mÃª cung (dfs, prim, wilson) | dfs |
| `--size` | KÃ­ch thÆ°á»›c (small, medium, large, xlarge) | small |
| `--episodes` | Sá»‘ episode huáº¥n luyá»‡n | 2000 |
| `--lr` | Learning rate | 0.1 |
| `--gamma` | Discount factor | 0.99 |
| `--epsilon` | Exploration rate | 1.0 |
| `--decay` | Epsilon decay | 0.995 |
| `--render` | Hiá»ƒn thá»‹ quÃ¡ trÃ¬nh train | False |

### 2. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh

```bash
# ÄÃ¡nh giÃ¡ Q-Learning
python backend/evaluation.py \
    --model_path models/q_learning/q_learning_15x15_2000ep.pkl \
    --model_type q_learning \
    --maze_type dfs \
    --maze_size 15 \
    --num_episodes 100 \
    --output_dir results/q_learning_eval

# ÄÃ¡nh giÃ¡ SARSA
python backend/evaluation.py \
    --model_path models/sarsa/sarsa_15x15_2000ep.pkl \
    --model_type sarsa \
    --maze_type dfs \
    --maze_size 15 \
    --num_episodes 100 \
    --output_dir results/sarsa_eval

# ÄÃ¡nh giÃ¡ DQN
python backend/evaluation.py \
    --model_path models/dqn/dqn_15x15_2000ep.pth \
    --model_type dqn \
    --maze_type dfs \
    --maze_size 15 \
    --num_episodes 100 \
    --output_dir results/dqn_eval
```

### 3. So sÃ¡nh cÃ¡c mÃ´ hÃ¬nh

```bash
# So sÃ¡nh Q-Learning vs SARSA
python backend/evaluation.py \
    --model_path models/q_learning/q_learning_15x15_2000ep.pkl \
    --model_type q_learning \
    --maze_type dfs \
    --maze_size 15 \
    --num_episodes 100 \
    --compare \
    --compare_path models/sarsa/sarsa_15x15_2000ep.pkl \
    --compare_type sarsa \
    --output_dir results/comparison_ql_vs_sarsa

# So sÃ¡nh Q-Learning vs DQN
python backend/evaluation.py \
    --model_path models/q_learning/q_learning_15x15_2000ep.pkl \
    --model_type q_learning \
    --maze_type dfs \
    --maze_size 15 \
    --num_episodes 100 \
    --compare \
    --compare_path models/dqn/dqn_15x15_2000ep.pth \
    --compare_type dqn \
    --output_dir results/comparison_ql_vs_dqn
```

### 4. Táº¡o heatmap visualization

```bash
# Táº¡o heatmap cho táº¥t cáº£ cÃ¡c thuáº­t toÃ¡n
python backend/get_heatmaps.py

# Output sáº½ Ä‘Æ°á»£c lÆ°u trong:
# - results/q_learning_heatmaps/
# - results/sarsa_heatmaps/
# - results/dqn_heatmaps/
```

### 6. Cháº¡y toÃ n bá»™ pipeline

**Option 1: Sá»­ dá»¥ng giao diá»‡n web (Khuyáº¿n nghá»‹)**
```bash
python backend/app.py
# Sau Ä‘Ã³ má»Ÿ http://localhost:8000 trong trÃ¬nh duyá»‡t
```

**Option 2: Sá»­ dá»¥ng script command line**

Táº¡o file `train_all.sh` (Linux/Mac) hoáº·c `train_all.bat` (Windows):

**Linux/Mac:**
```bash
#!/bin/bash
# train_all.sh

echo "Training Q-Learning..."
python backend/training.py --agent q_learning --maze dfs --size medium --episodes 2000

echo "Training SARSA..."
python backend/training.py --agent sarsa --maze dfs --size medium --episodes 2000

echo "Training DQN..."
python backend/training.py --agent dqn --maze dfs --size medium --episodes 2000

echo "Creating heatmaps..."
python backend/get_heatmaps.py

echo "Training completed!"
```

**Windows:**
```batch
@echo off
REM train_all.bat

echo Training Q-Learning...
python backend/training.py --agent q_learning --maze dfs --size medium --episodes 2000

echo Training SARSA...
python backend/training.py --agent sarsa --maze dfs --size medium --episodes 2000

echo Training DQN...
python backend/training.py --agent dqn --maze dfs --size medium --episodes 2000

echo Creating heatmaps...
python backend/get_heatmaps.py

echo Training completed!
```

## ğŸ§  Thuáº­t toÃ¡n

### Q-Learning
- **Loáº¡i**: Off-policy
- **Æ¯u Ä‘iá»ƒm**: Há»™i tá»¥ nhanh, há»c tá»« kinh nghiá»‡m tá»‘i Æ°u
- **NhÆ°á»£c Ä‘iá»ƒm**: CÃ³ thá»ƒ overestimate giÃ¡ trá»‹ Q

### SARSA
- **Loáº¡i**: On-policy
- **Æ¯u Ä‘iá»ƒm**: An toÃ n hÆ¡n, phÃ¹ há»£p vá»›i mÃ´i trÆ°á»ng stochastic
- **NhÆ°á»£c Ä‘iá»ƒm**: Há»™i tá»¥ cháº­m hÆ¡n Q-Learning

### DQN (Deep Q-Network)
- **Loáº¡i**: Off-policy vá»›i neural network
- **Æ¯u Ä‘iá»ƒm**: Xá»­ lÃ½ khÃ´ng gian tráº¡ng thÃ¡i lá»›n, kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a tá»‘t
- **NhÆ°á»£c Ä‘iá»ƒm**: Cáº§n nhiá»u dá»¯ liá»‡u, tÃ­nh toÃ¡n phá»©c táº¡p

## ğŸ“Š Káº¿t quáº£

Sau khi huáº¥n luyá»‡n, cÃ¡c mÃ´ hÃ¬nh sáº½ Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c `models/`:
- Q-Learning: `models/q_learning/q_learning_{size}x{size}_{episodes}ep.pkl`
- SARSA: `models/sarsa/sarsa_{size}x{size}_{episodes}ep.pkl`
- DQN: `models/dqn/dqn_{size}x{size}_{episodes}ep.pth`

Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ sáº½ bao gá»“m:
- Tá»· lá»‡ thÃ nh cÃ´ng
- Sá»‘ bÆ°á»›c trung bÃ¬nh
- Pháº§n thÆ°á»Ÿng trung bÃ¬nh
- Heatmap chÃ­nh sÃ¡ch vÃ  giÃ¡ trá»‹
- So sÃ¡nh hiá»‡u suáº¥t giá»¯a cÃ¡c thuáº­t toÃ¡n

## ğŸ”§ Cáº¥u hÃ¬nh

CÃ¡c tham sá»‘ cáº¥u hÃ¬nh cÃ³ thá»ƒ chá»‰nh sá»­a trong `backend/utils/config.py`:

```python
# KÃ­ch thÆ°á»›c mÃª cung
MAZE_SIZES = {
    "small": (11, 11),
    "medium": (15, 15),
    "large": (21, 21),
    "xlarge": (31, 31)
}

# Tham sá»‘ há»c
LEARNING_RATE = 0.1
DISCOUNT_FACTOR = 0.99
EXPLORATION_RATE = 1.0
EXPLORATION_DECAY = 0.995
MIN_EXPLORATION = 0.01

# Pháº§n thÆ°á»Ÿng
MOVE_REWARD = -0.05
WALL_PENALTY = -2.0
GOAL_REWARD = 100.0
TIME_PENALTY = -0.001
MAX_STEPS = 2000
```

## ğŸ‘¥ TÃ¡c giáº£

- TÃªn: NGUYá»„N NGá»ŒC DUY
- Email: ngocduy0217@gmail.com

## ğŸ“„ License

